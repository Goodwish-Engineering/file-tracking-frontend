import multiprocessing
from collections import defaultdict
class MapReduce:
    def __init__(self, num_workers=2):
        self.num_workers = num_workers
    def map(self, chunk):
        word_counts = defaultdict(int)
        for word in chunk.split():
            word_counts[word] += 1
        return list(word_counts.items())
    def shuffle_sort(self, mapped_data):
        shuffled_data = defaultdict(list)
        for sublist in mapped_data:
            for word, count in sublist:
                shuffled_data[word].append(count)
        return shuffled_data
    def reduce(self, shuffled_data):
        return {word: sum(counts) for word, counts in shuffled_data.items()}
    def execute(self, text):
        chunks = text.split("\n")
        # Mapping part 
        with multiprocessing.Pool(self.num_workers) as pool:
            mapped_data = pool.map(self.map, chunks)
        # Sort and shuffle part
        shuffled_data = self.shuffle_sort(mapped_data)
        # Reduce part
        final_result = self.reduce(shuffled_data)
        return final_result
if __name__ == "__main__":
    text_corpus = """Panda Koala Kangaroo
                    Kangaroo Koala Sloth
                    Sloth Panda Lemur
                    Lemur Koala Panda
                    Meerkat Sloth Koala"""
    
    map_reduce = MapReduce(num_workers=3)
    result = map_reduce.execute(text_corpus)
    print("Final Word Count:", result)
